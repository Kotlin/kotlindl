{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<em><sub>This page is available as an executable or viewable <strong>Jupyter Notebook</strong></sub></em>\n",
    "<br/><br/>\n",
    "<a href=\"https://mybinder.org/v2/gh/avan1235/KotlinDL/notebooks?filepath=docs%2Fcreate_your_first_nn.ipynb\"\n",
    "   target=\"_parent\">\n",
    "   <img align=\"left\"\n",
    "        src=\"https://mybinder.org/badge_logo.svg\"\n",
    "        height=\"20\">\n",
    "</a>\n",
    "<a href=\"https://nbviewer.jupyter.org/github/avan1235/KotlinDL/blob/notebooks/docs/create_your_first_nn.ipynb\"\n",
    "   target=\"_parent\">\n",
    "   <img align=\"right\"\n",
    "        src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\"\n",
    "        height=\"20\">\n",
    "</a>\n",
    "<br/><br/>"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "@file:DependsOn(\"org.jetbrains.kotlinx:kotlin-deeplearning-api:0.2.0\")"
   ],
   "execution_count": 1,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create your first Neural Network with KotlinDL\n",
    "\n",
    "In this tutorial, we'll use KotlinDL to create a neural networkou'll learn about the basic building blocks and concepts needed to get started with Deep Learning. In subsequent tutorials, you will learn how to train this neural network and use the resulting model to generate predictions. No previous deep learning experience is required to get started with these tutorials.\n",
    "\n",
    "## Image Classification\n",
    "\n",
    "One of the most common applications of Deep Learning is image classification. \n",
    "In this tutorial, we'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), which you can think of as an image classification \"Hello World.\" \n",
    "This dataset contains 70,000 images that fall into ten different categories of clothing items. \n",
    "Each example is a 28x28 grayscale image associated with a single label that matches one of the 10 classes. \n",
    "Here are the labels and how they map to the actual classes:\n",
    "\n",
    "| Label        | Class           | \n",
    "| ------------- |:-------------:| \n",
    "| 0      | T-shirt/top | \n",
    "| 1      | Trousers |\n",
    "| 2      | Pullover |\n",
    "| 3      | Dress |\n",
    "| 4      | Coat |\n",
    "| 5      | Sandals |\n",
    "| 6      | Shirt |\n",
    "| 7      | Sneakers |\n",
    "| 8      | Bag |\n",
    "| 9      | Ankle boots |\n",
    "\n",
    "For this example, we are planning to use a numeric representation for string categories, called string-to-number encoding. \n",
    "We'll later use this to get human-readable predictions:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "val labelsMap = mapOf(\n",
    "        0 to \"T-shirt/top\",\n",
    "        1 to \"Trousers\",\n",
    "        2 to \"Pullover\",\n",
    "        3 to \"Dress\",\n",
    "        4 to \"Coat\",\n",
    "        5 to \"Sandals\",\n",
    "        6 to \"Shirt\",\n",
    "        7 to \"Sneakers\",\n",
    "        8 to \"Bag\",\n",
    "        9 to \"Ankle boots\"\n",
    ")"
   ],
   "execution_count": 2,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When working with other datasets, you may need to look up this mapping in a metadata file that comes with a dataset. \n",
    "You may even need to encode it yourself if the original data contains the string representation of classes instead of integers.\n",
    "\n",
    "Here's what the images themselves look like:\n",
    "\n",
    "![Fashion MNIST dataset](images/fashion-mnist-sprite.png)\n",
    "\n",
    "We will build and train a neural network that will classify images like these into given categories.\n",
    "If you're going to follow along with this tutorial, you'll need to download the dataset, which you can find in the KotlinDL examples as dataset providing funciton. Usually, when working with real world data, collecting the data may be a really hard part of the image training process, but in this tutorial we will use the sample dataset from the library (let's see to it's implementation for better understanding)."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import org.jetbrains.kotlinx.dl.dataset.fashionMnist\n",
    "\n",
    "val dataset = fashionMnist()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Extracting 60000 images of 28x28 from /workspace/cache/datasets/fashionmnist/train-images-idx3-ubyte.gz\n",
      "Extracting 60000 labels from /workspace/cache/datasets/fashionmnist/train-labels-idx1-ubyte.gz\n",
      "Extracting 10000 images of 28x28 from /workspace/cache/datasets/fashionmnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting 10000 labels from /workspace/cache/datasets/fashionmnist/t10k-labels-idx1-ubyte.gz\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a Neural Network\n",
    "\n",
    "Let's start by defining the structure of our neural network. The basic building block of a neural network is a **layer**. \n",
    "So, to define a neural network, we need to describe what layers it should consist of. \n",
    " \n",
    "The goal of the layers is to capture aspects of data representations during the training phase. \n",
    "With enough data, layers, and training iterations, \n",
    "neural networks can capture enough complexity to deliver outstanding results on many tasks.\n",
    "\n",
    "The neural network that we will define here is called _Multilayer Perceptron (MLP)_. \n",
    "Consisting of multiple fully connected layers (named also the dense layers), it is one of the simplest neural networks. \n",
    "Each neuron in a given layer receives outputs from all the neurons in the previous layer and sends its output to all the neurons in the next layer.\n",
    "\n",
    "Here's how we define a neural network that consists of a few simple layers in a sequence:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import org.jetbrains.kotlinx.dl.api.core.Sequential\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.core.Input\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.reshaping.Flatten\n",
    "import org.jetbrains.kotlinx.dl.api.core.layer.core.Dense\n",
    "\n",
    "val model = Sequential.of(\n",
    "    Input(28, 28, 1),\n",
    "    Flatten(),\n",
    "    Dense(300),\n",
    "    Dense(100),\n",
    "    Dense(10)\n",
    ")"
   ],
   "execution_count": 4,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quite simple, right? Let's take a closer look at what we have defined here. \n",
    "First, we specify the kind of input we will pass to this neural network. \n",
    "We have images that are 28 x 28 pixels and only have one color channel. \n",
    "Thus the input will be an array of size 28 x 28 x 1 where each value in the array\n",
    "will correspond to the grayscale of the pixel from image.\n",
    "\n",
    "The first layer is `Flatten()`. It simply reformats the data, \n",
    "transforming the three-dimensional input array into a one-dimensional array \n",
    "with 784 elements $(28 \\cdot 28 \\cdot 1 = 784)$.\n",
    "\n",
    "Next, we've got a sequence of three `Dense()` layers. \n",
    "Dense layers, also called fully connected layers, \n",
    "are the most common layers in all kinds of neural network architectures. \n",
    "For each Dense layer, we have specified its size. \n",
    "The first one has 300 neurons, the second one has 100 neurons, \n",
    "and the last one has 10 neurons (remember, we have 10 different classes to predict).\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "In this case, we only specified the size of each Dense layer. \n",
    "There are many other layer parameters that you can tweak. \n",
    "Kotlin DL comes with sensible defaults where possible to help you get started quickly. \n",
    "Here are the defaults that are used for `Dense` layers: \n",
    "* `activation = Activations.Relu`. Simply put, in a neuron, a weighted sum of the inputs plus bias is calculated, then an activation function is applied. \n",
    "This output is then passed along. \n",
    "Most activation functions are differentiable and add non-linearity, which allows deep learning networks to capture the complexity of a dataset. \n",
    "There’s a variety of non-linear activation functions, but [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) is one of the most commonly used ones. \n",
    "* `kernelInitializer = HeNormal()`, `biasInitializer = HeUniform()`. Before a neural network is trained, all the parameters need to be initialized. \n",
    "While this can be done with random numbers or zeros, these default initializer algorithms accelerate the training of the neural network.  \n",
    " \n",
    "**If you have used a framework like Keras before, note that the defaults may be different in Kotlin DL.**\n",
    "\n",
    "---\n",
    "\n",
    "## Compiling a neural network \n",
    "In the previous step, we defined the structure of our neural network. \n",
    "Next, we need to decide how it will be trained. What optimization algorithm will be used? \n",
    "What do we want to optimize for? And how will we evaluate progress? \n",
    "We will provide this information in the `compile()` method:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import org.jetbrains.kotlinx.dl.api.core.optimizer.Adam\n",
    "import org.jetbrains.kotlinx.dl.api.core.loss.Losses\n",
    "import org.jetbrains.kotlinx.dl.api.core.metric.Metrics\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(),\n",
    "    loss = Losses.SOFT_MAX_CROSS_ENTROPY_WITH_LOGITS,\n",
    "    metric = Metrics.ACCURACY\n",
    ")\n",
    "\n",
    "model.close()"
   ],
   "execution_count": 5,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's dive into some details of the provided structure:\n",
    "* `model`  is an AutoCloseable object, allowing you to leverage the `use` construct. If you don’t want to use the `use` Kotlin construction, do not forget to call `model.close()`. \n",
    "* [Adam](https://arxiv.org/abs/1412.6980) is the optimization algorithm that our neural network will use to update the weights in its nodes as it trains.\n",
    "* The loss function is used to optimize your model.\n",
    "* This is the function that will be minimized by the optimizer. \n",
    "Here, the last layer of the model gives us 10 numbers, each representing the probability of the example belonging to a given class. \n",
    "*Softmax Crossentropy with logits* measures the probability of error.\n",
    "* Metrics allow you to monitor the training and evaluation of the model. Accuracy simply represents the percentage of correct predictions out of all the predictions made.  \n",
    "\n",
    "At this point, we can call the `summary()` method to get a printout of the neural network's architecture. \n"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "val summary = model.summary().joinToString(separator=\"\\n\")\n",
    "println(summary)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "input_1(Input)                         [None, 28, 28, 1]         0\n",
      "flatten_2(Flatten)                     [None, 784]               0\n",
      "dense_3(Dense)                         [None, 300]               235500\n",
      "dense_4(Dense)                         [None, 100]               30100\n",
      "dense_5(Dense)                         [None, 10]                1010\n"
     ],
     "output_type": "stream"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the second column we see the shape of the valid inputs for the next layers while the third columns counts the number of trainable parameters of each layer.\n",
    "\n",
    "Great! We have now defined the structure of our neural network, specified the optimization algorithm that will be used during its training, and identified accuracy as the metric we will use to gauge its success.\n",
    "\n",
    "In the [following tutorial](training_a_model.ipynb), you'll learn how to train this model on the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)."
   ],
   "attachments": {},
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}