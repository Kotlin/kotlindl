{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "name": "python_train_export_cifar_10.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38-wD4Lv9nkt"
   },
   "source": [
    "<em><sub>This page is available as an executable or viewable <strong>Jupyter Notebook</strong></sub></em>\n",
    "<br/><br/>\n",
    "<a href=\"https://mybinder.org/v2/gh/avan1235/KotlinDL/notebooks?filepath=docs%2Fpython_train_export_cifar_10.ipynb\"\n",
    "   target=\"_parent\">\n",
    "   <img align=\"left\"\n",
    "        src=\"https://mybinder.org/badge_logo.svg\"\n",
    "        height=\"20\">\n",
    "</a>\n",
    "<a href=\"https://nbviewer.jupyter.org/github/avan1235/KotlinDL/blob/notebooks/docs/python_train_export_cifar_10.ipynb\"\n",
    "   target=\"_parent\">\n",
    "   <img align=\"right\"\n",
    "        src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\"\n",
    "        height=\"20\">\n",
    "</a>\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGrbzDqk4hZ7"
   },
   "source": [
    "# Exporting Python Keras model\n",
    "\n",
    "In this scenario we assume that we already have some code with neural netowork definition in Python that includes its training and data extraction. There are a few common scenarios when we would like to reuse this code indirecly and exporting the model seems to be the easiest approach."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kD8ldF2-3Q4M"
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gt8kTA94_80"
   },
   "source": [
    "As an example, we use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) to train our neural network in Python which doesn't need a lot of preprocessing work as it is already prepared by Keras."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AOKC8-Xy3Q4R"
   },
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPpiIxR35XKk"
   },
   "source": [
    "We define our neural network as a common convolutional architecture with maxpooling layers for decreasing the image size. We end up with 10 outputs from the network as there are 10 labels to be detected in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aE3v5dJY3Q4S"
   },
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)), \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uMxsEfRd3Q4T",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "572af036-a449-40f9-db28-ba7840508abe"
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcOtb2Ld3Q4V",
    "outputId": "552e7bf4-a7c8-4be4-bdb9-ac7a01d3f210"
   },
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 1.5514 - accuracy: 0.4319 - val_loss: 1.2919 - val_accuracy: 0.5312\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.2032 - accuracy: 0.5735 - val_loss: 1.1187 - val_accuracy: 0.5980\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 1.0546 - accuracy: 0.6273 - val_loss: 1.0149 - val_accuracy: 0.6435\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.9633 - accuracy: 0.6613 - val_loss: 1.0402 - val_accuracy: 0.6338\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.8887 - accuracy: 0.6873 - val_loss: 0.9340 - val_accuracy: 0.6757\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.8290 - accuracy: 0.7115 - val_loss: 0.8936 - val_accuracy: 0.6910\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.7923 - accuracy: 0.7240 - val_loss: 0.9299 - val_accuracy: 0.6798\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.7465 - accuracy: 0.7389 - val_loss: 0.8878 - val_accuracy: 0.6993\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.7120 - accuracy: 0.7505 - val_loss: 0.8594 - val_accuracy: 0.7073\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.6749 - accuracy: 0.7633 - val_loss: 0.8707 - val_accuracy: 0.7050\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OjVTyQCA3Q4W",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3d3e16b4-1d89-4467-9203-2529342aba78"
   },
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.8707 - accuracy: 0.7050\n",
      "0.7049999833106995\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ywgASUA5ypw"
   },
   "source": [
    "After training process done with `fit` method we saw that the evaluated model achieves over 70% of accuracy on the unseen test data.\n",
    "\n",
    "Now we can save this model structure to `.json` file as well the weights form the model that we obtained during training process to standard data file format named `Hierarchical Data Format` or just `HDF5`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oFV46pLS3Q4X"
   },
   "source": [
    "model.save('keras-cifar-10/weights', save_format='h5')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"keras-cifar-10/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ],
   "execution_count": 7,
   "outputs": []
  }
 ]
}